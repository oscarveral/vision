% bt2.tex — LaTeX article template
% Compile: pdflatex bt2.tex && biber bt2 && pdflatex bt2.tex && pdflatex bt2.tex

\documentclass[11pt,a4paper]{article}

% Encoding & fonts
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{microtype}

% Page layout
\usepackage{geometry}
\geometry{margin=1in}

% Math & symbols
\usepackage{amsmath,amssymb,amsthm}

% Graphics & tables
\usepackage{graphicx}
\usepackage{caption,subcaption}
\usepackage{booktabs}
\usepackage{float}

% Code listings
\usepackage{listings}
\usepackage{xcolor}
\lstset{
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    breaklines=true
}

% Images folder
\graphicspath{{images/bt2/}}

% References, hyperlinks, cross-references
\usepackage[hidelinks]{hyperref}
\usepackage{cleveref}

% Units
\usepackage{siunitx}

% Bibliography (biblatex + biber)
\usepackage{biblatex}
\addbibresource{bt2.bib} % create refs.bib next to this file

\begin{document}

\section{BT2 - Estimación robusta de parámtetros}

En esta sección tratamos la detección de rectas y otras formas geométricas características en el ámbito de las señales
de tráfico, candidatas idóneas sobre el papel para ser detectadas mediante técnicas de estimación robusta de parámetros
vistas en la asignatura. Comenzamos presentando el subconjunto de imágenes seleccionado para ejemplificar los métodos que
aquí explicamos, mostrando el resultado la aplicación del pipeline propuesto en la sección anterior para la detección
de líneas de borde. Además, proponemos otro método método de detección de bordes muy enfocado a este tipo de imágenes basado
en la conversión del espacio de color RGB a HSV y la posterior umbralización del canal de saturación. A continuación, exponemos
nuestra implementación en C para la detección de líneas y circunferencias con RANSAC y mostramos los resultados obtenidos.
Finalmente, presentamos una serie de conclusiones y posibles líneas de trabajo futuras.

\subsection{Dataset y preprocesamiento}

Del conjunto de imágenes expuesto \cite{alibeigi2023zod} hemos seleccionado las siguientes 11 imágenes:

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{img00.jpg}
        \caption{Imagen 0}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{img01.jpg}
        \caption{Imagen 1}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{img02.jpg}
        \caption{Imagen 2}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{img03.jpg}
        \caption{Imagen 3}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{img04.jpg}
        \caption{Imagen 4}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{img05.jpg}
        \caption{Imagen 5}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{img06.jpg}
        \caption{Imagen 6}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{img07.jpg}
        \caption{Imagen 7}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{img08.jpg}
        \caption{Imagen 8}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{img09.jpg}
        \caption{Imagen 9}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{img10.jpg}
        \caption{Imagen 10}
    \end{subfigure}
    \caption{Imágenes seleccionadas del conjunto ZOD para la detección de líneas de borde.}
    \label{fig:bt2_dataset}
\end{figure}

Como vemos, son imágenes en entornos urbanos con múltiples señales de tráfico. Incluimos una imagen con señales de obras (Imagen 4), una sin edificios (Imagen 7), una con hojas y muchas sombras (Imagen 8) y una nocturna (Imagen 10) para contar con cierta variedad.

A estas imágenes les aplicamos el siguiente preprocesamiento:
\begin{itemize}
    \item Corrección de la distorsión de Kannala Brandt.
    \item Reescalado por un factor de 0'5.
    \item Aplicación de un filtro de medianas de 5x5 para reducir el ruido.
\end{itemize}
El escalado se ha llevado a cabo para agilizar la salidas en el notebook. Ha sido llevado a cabo mediante la función \texttt{cv2.resize()} de OpenCV con el método de interpolación 
\texttt{INTER\_AREA}, ideal para reducciones. El resultado de este preprocesamiento se muestra en la \cref{fig:bt2_preprocessed}. Las dimensiones finales de las imágenes son de 1924x1084 píxeles.

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{pre_img00.jpg}
        \caption{Imagen 0 preprocesada}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{pre_img01.jpg}
        \caption{Imagen 1 preprocesada}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{pre_img02.jpg}
        \caption{Imagen 2 preprocesada}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{pre_img03.jpg}
        \caption{Imagen 3 preprocesada}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{pre_img04.jpg}
        \caption{Imagen 4 preprocesada}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{pre_img05.jpg}
        \caption{Imagen 5 preprocesada}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{pre_img06.jpg}
        \caption{Imagen 6 preprocesada}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{pre_img07.jpg}
        \caption{Imagen 7 preprocesada}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{pre_img08.jpg}
        \caption{Imagen 8 preprocesada}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{pre_img09.jpg}
        \caption{Imagen 9 preprocesada}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{pre_img10.jpg}
        \caption{Imagen 10 preprocesada}
    \end{subfigure}
    \caption{Imágenes preprocesadas del conjunto ZOD para la detección de líneas de borde.}
    \label{fig:bt2_preprocessed}
\end{figure}

\subsection{Detección de bordes}
Para la detección de bordes hemos implementado dos métodos diferentes. El primero de ellos es el ya explicado en la
sección anterior basado en la detección de bordes de Canny. La segunda aproximación es una segmentación por color seguida
por una dilatación. En ambos casos, vamos a hacer una transformación previa de la imagen al espacio de color HSV.

\subsubsection{Espacio de color HSV}
El espacio de color HSV (Hue, Saturation, Value) \cite{wikipedia_hsv_modelo_color} es un modelo de color que representa los colores de una manera más intuitiva que el espacio RGB. 
En este modelo cada canal representa:

\begin{itemize}
    \item Hue (Matiz): es una escala circular que representa el tipo de color (rojo, verde, azul, etc.) y se mide en grados (0-360°), aunque en OpenCV se escala a un rango de 0 a 179.
    \item Saturation (Saturación): representa la intensidad del color, donde 0 es un tono de gris y 255 es el color completo.
    \item Value (Valor): representa el brillo del color. Es el clásico concepto de luminosidad, donde 0 es negro y 255 es el color más brillante.
\end{itemize}

Las señales de tráfico, al tener que ser fácilmente detectables por el ojo humano en diversas condiciones de iluminación y clima, se diseñan con colores brillantes y contrastantes. 
Esto las hace ideales para ser segmentadas en el espacio de color HSV, donde los cambios en la iluminación afectan menos a la percepción del color.
Identificamos que todas las principales señales cuentan con el color rojo o el azul, incluso aquellas que encontramos en obras viales que sustituyen el color blanco por amarillo.

% vemos lado a lado h y s para las imagenes 0, 8 y 10
\begin{figure}[H]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\linewidth]{hue_img00.jpg}
        \caption{Hue imagen 0}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\linewidth]{sat_img00.jpg}
        \caption{Saturación imagen 0}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\linewidth]{hue_img08.jpg}
        \caption{Hue imagen 8}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\linewidth]{sat_img08.jpg}
        \caption{Saturación imagen 8}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\linewidth]{hue_img10.jpg}
        \caption{Hue imagen 10}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\linewidth]{sat_img10.jpg}
        \caption{Saturación imagen 10}
    \end{subfigure}
    \caption{Canales de Hue y Saturación para las imágenes 0, 8 y 10.}
    \label{fig:hue_vs_saturation}
\end{figure}

En la escala de matiz, el rojo se corresponde con valores cercanos a 0 y el azul a 120.
Como vemos en la \cref{fig:hue_vs_saturation}, el canal de saturación resalta mucho más las señales de tráfico que el canal de matiz.
Es una excepción la imagen nocturna (Imagen 10), donde el canal de saturación apenas resalta las señales debido a la baja iluminación y
a la presencia de luces artificiales que distorsionan los colores. El canal de matiz, por otro lado, es prometedor en la imagen 10 al 
resaltar las señales de la zona propiamente iluminada ya que estas están fabricadas con un material que permite reflejar la luz de manera más efectiva durante la noche.

\subsubsection{Operador de Canny en espacio HSV}

Aplicando el pipeline de detección de bordes basado en Canny explicado en la sección anterior, pero esta vez en el espacio HSV, 
acabamos concluyendo que una ponderación de los canales H y S con pesos 0.25 y 0.75 respectivamente daba los mejores bordes.
El proceso completo es el siguiente:

\begin{enumerate}
    \item Convertir la imagen de RGB a HSV.
    \item Calcular la imagen ponderada: $I_{weighted} = 0.25 \cdot I_H + 0.75 \cdot I_S$.
    \item Suavizar $I_{weighted}$ con un filtro Gaussiano de $\sigma=0.4$.
    \item Aplicar el operador de Canny a $I_{weighted}$ con umbrales 150 y 250.
\end{enumerate}

El resultado de este proceso se muestra en la \cref{fig:bt2_canny_hsv}.

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{canny_hsv_img00.jpg}
        \caption{Canny HSV imagen 0}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{canny_hsv_img01.jpg}
        \caption{Canny HSV imagen 1}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{canny_hsv_img02.jpg}
        \caption{Canny HSV imagen 2}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{canny_hsv_img03.jpg}
        \caption{Canny HSV imagen 3}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{canny_hsv_img04.jpg}
        \caption{Canny HSV imagen 4}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{canny_hsv_img05.jpg}
        \caption{Canny HSV imagen 5}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{canny_hsv_img06.jpg}
        \caption{Canny HSV imagen 6}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{canny_hsv_img07.jpg}
        \caption{Canny HSV imagen 7}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{canny_hsv_img08.jpg}
        \caption{Canny HSV imagen 8}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{canny_hsv_img09.jpg}
        \caption{Canny HSV imagen 9}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{canny_hsv_img10.jpg}
        \caption{Canny HSV imagen 10}
    \end{subfigure}
    \caption{Resultados del operador de Canny en espacio HSV para las imágenes seleccionadas. Los bordes se muestran dilatados para mayor visibilidad.}
    \label{fig:bt2_canny_hsv}
\end{figure}

\subsubsection{Segmentación por color y dilatación}

El segundo método de detección de bordes que hemos implementado se basa en un segmentación por color en el espacio HSV.
Después de identificar que las señales de tráfico se caracterizan por colores azules y rojos muy saturados, hemos optado por umbralizar
segmentar la imagen a partir de los rangos de matiz [165, 180] y [0, 15] para el rojo y [90, 130] para el azul. Además, aplicamos 
una umbralización en el canal de saturación para eliminar colores poco saturados, estableciendo un umbral en 90. El proceso completo es:

\begin{enumerate}
    \item Convertir la imagen de RGB a HSV.
    \item Crear una máscara binaria donde se cumplan las siguientes condiciones:
    \begin{itemize}
        \item El canal de saturación sea mayor que 90.
        \item El canal de matiz esté en los rangos [165, 180] o [0, 15] (rojo) o [90, 130] (azul).
    \end{itemize}
    \item Eliminar las regiones pequeñas mediante un filtrado de componentes conexas con un umbral de 50 píxeles.
    \item Aplicar una dilatación circular de un pixel de grosor y sustraer la máscara original para obtener los bordes.
\end{enumerate}

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{seg_dilate_img00.jpg}
        \caption{Segmentación dilatada imagen 0}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{seg_dilate_img01.jpg}
        \caption{Segmentación dilatada imagen 1}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{seg_dilate_img02.jpg}
        \caption{Segmentación dilatada imagen 2}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{seg_dilate_img03.jpg}
        \caption{Segmentación dilatada imagen 3}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{seg_dilate_img04.jpg}
        \caption{Segmentación dilatada imagen 4}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{seg_dilate_img05.jpg}
        \caption{Segmentación dilatada imagen 5}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{seg_dilate_img06.jpg}
        \caption{Segmentación dilatada imagen 6}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{seg_dilate_img07.jpg}
        \caption{Segmentación dilatada imagen 7}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{seg_dilate_img08.jpg}
        \caption{Segmentación dilatada imagen 8}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{seg_dilate_img09.jpg}
        \caption{Segmentación dilatada imagen 9}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\linewidth]{seg_dilate_img10.jpg}
        \caption{Segmentación dilatada imagen 10}
    \end{subfigure}
    \caption{Resultados de la segmentación por color y dilatación para las imágenes seleccionadas. Los bordes se muestran dilatados para mayor visibilidad.}
    \label{fig:bt2_seg_dilate}
\end{figure}

\subsection{Comparación de resultados}

Aunque ambos métodos ofrecen resultados aceptables, hemos observado que la segmentación por color y dilatación tiende a ser más robusta en condiciones de iluminación variables y en presencia de ruido.
Lo que nos hace decantarnos por este método es el buen funcionamiento en la imagen nocturna (Imagen 10), donde el operador de Canny en espacio HSV no logra detectar los bordes de las señales de tráfico debido a la baja iluminación y al ruido introducido por las luces artificiales. 
Esta segunda técnica también parece generar menos falsos positivos en ciertas imágenes con fondos complejos.

\subsection{Detección de features con RANSAC}

Para la detección de features en imágenes hemos creado una clase en Python llamada \texttt{FeatureExtractor}. 
En particular, la clase sirve de interfaz para la detección de líneas, segmentos y circunferencias mediante las ideas de RANSAC.

\subsubsection{Detección de rectas}

Una vez contamos con una imagen de bordes, la propuesta de RANSAC es la siguiente:

\begin{enumerate}
    \item Seleccionar aleatoriamente dos puntos de borde para definir una línea candidata.
    \item Calcular la distancia perpendicular de todos los puntos de borde a esta línea.
    \item Contar el número de inliers, es decir, puntos cuya distancia a la línea es menor que un umbral predefinido.
    \item Repetir los pasos 1-3 un número fijo de veces o hasta que se alcance un número suficiente de inliers.
    \item Seleccionar la línea con el mayor número de inliers como la mejor estimación.
    \item Opcionalmente, refinar la línea utilizando todos los inliers mediante un ajuste por mínimos cuadrados.
\end{enumerate}

Nosotros hemos decidido implementar nuestra versión en C, la cual puede ser consultada en \texttt{src/dgst/ffi/ransac.c} bajo el 
nombre de \texttt{ransac\_line\_fitting}. El procedimiento implementado es el recién descrito. Los parámetros que necesita son:
\begin{itemize}
    \item input: Puntero a un array de puntos de borde.
    \item width, height: Dimensiones de la imagen.
    \item distance\_threshold: Umbral de distancia para considerar un punto como inlier.
    \item max\_iterations: Número de iteraciones de RANSAC.
    \item max\_lsq\_iterations: Número de iteraciones para el ajuste por mínimos cuadrados.
    \item min\_inlier\_count: Número mínimo de inliers para aceptar una línea.
\end{itemize}
El resultado es una recta representada en forma ax + by + c = 0 mediante los parámetros a, b y c (en caso de que se haya encontrado alguna línea).
Adicionalmente, como funcionalidad en python incluimos la posibilidad de eliminar los inliers de la recta detectada para facilitar la detección de 
otras líneas en iteraciones posteriores.

Aplicando este método a nuestras imágenes de bordes exigiendo un mínimo de 200 inliers en la primera iteración y un mínimo de 50 tras aplicar 
RANSAC hasta 150 veces obtenemos imágenes como las mostradas en la \cref{fig:bt2_detected_lines}.

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\linewidth]{lines_image00.jpg}
        \caption{Líneas detectadas imagen 0}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\linewidth]{lines_image08.jpg}
        \caption{Líneas detectadas imagen 8}
    \end{subfigure}
    \caption{Resultados de la detección de líneas mediante RANSAC en las imágenes 0 y 8.}
    \label{fig:bt2_detected_lines}
\end{figure}

El algoritmo funciona bien detectando las rectas, pero resulta ser muy sensible al ruido. En cuanto hay una cantidad no demasiado alta de nubes de puntos alineados las rectas encontradas se ajustan a este ruido. Para solucionar esto, podríamos aumentar el número mínimo de inliers requerido, pero a costa de sacrificar algunas rectas más pequeñas. 

Debido a que las señales de tráfico ocupan una sección relativamente pequeña de la imagen, proponemos aplicar RANSAC mediante un algoritmo de ventana deslizante. De esta forma, permitimos eliminar esas rectas que se ajustan al ruido y detectar bordes más pequeños al poder reducir el número mínimo de inliers necesarios para determinar una recta. Para ello, utilizamos un nuevo método extractor de características llamado  \texttt{windowed\_ransac\_line\_fitting}.

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\linewidth]{linesw_image00.jpg}
        \caption{Líneas detectadas imagen 0}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\linewidth]{linesw_image08.jpg}
        \caption{Líneas detectadas imagen 8}
    \end{subfigure}
    \caption{Resultados de la detección de líneas mediante RANSAC en ventana deslizante en las imágenes 0 y 8.}
    \label{fig:bt2_detected_lines}
\end{figure}

Como vemos, a pesar de utilizar en este caso un umbral de detección de inliers mayor (1.4 frente a 0.7 en el caso anterior) y un 
requerimiento menor de inliers por iteración, el método de ventana deslizante consigue detectar las rectas relevantes de la imagen sin verse tan afectado por el ruido.

\subsubsection{Detección de segmentos}

Otro problema de la baja ocupancia de las señales es que las rectas cubren innecesariamente toda la imagen. 
Sería ideal limitar la expresión de las mismas a los segmentos donde realmente hay señales.
Es por esto que proponemos un método para inferir segmentos a partir de las rectas detectadas. El procedimiento, 
implementado mediante el método \texttt{get\_line\_support} de la clase FeatureExtractor, es el siguiente:

\begin{enumerate}
    \item Se proporciona una recta en forma ax + by + c = 0, desactivando la eliminación de inliers tras la detección.
    \item Se reobtienen los inliers de la línea en la imagen de bordes.
    \item Los inliers se proyectan ortogonalmente sobre la recta para obtener sus coordenadas 1D.
    \item Se calcula la densidad de inliers a lo largo de la línea.
    \item Se identifica el segmento maximal con densidad que supere un umbral dado.
\end{enumerate}

Para llevar a cabo el último paso, hemos utilizado una versión adaptada del Algoritmo de Kadane \cite{kadane}, un algoritmo de programación dinámica que resuelve el 
problema \textbf{Maximum Subarray Problem} de encontrar un subarray de suma máxima. Los pasos de esta adaptación son, partiendo de una serie de puntos en 1D (proyecciones sobre la recta):

\begin{enumerate}
    \item Se establece un umbral de densidad $\mu$ (número de inliers por unidad de longitud).
    \item Se construye un array auxiliar A, de forma que A[i] representa la contribucón de densidad del i-ésimo intervalo $A_i = 1 - \mu\times(p_{i+1} - p_i)$
    \item Se inicializan las variables:
    \begin{itemize}
        \item max\_sum = 0
        \item current\_sum = 0
        \item start\_index = 0
        \item best\_start = -1
        \item best\_end = -1
    \end{itemize}
    \item Se recorren los elementos del array A guardando las sumas acumuladas:
    \begin{itemize}
        \item current\_sum += A[i]
        \item Si current\_sum > max\_sum:
        \begin{itemize}
            \item max\_sum = current\_sum
            \item best\_start = start\_index
            \item best\_end = i
        \end{itemize}
        \item Si current\_sum < 0:
        \begin{itemize}
            \item current\_sum = 0
            \item start\_index = i + 1
        \end{itemize}
    \end{itemize}
    \item Se devuelve el segmento [best\_start, best\_end].
\end{enumerate}

Una de las bondades de este algoritmo es que funciona en tiempo lineal con respecto al número de inliers. Podemos verlo en acción sobre una región de la imagen 0 en la \cref{fig:kadane_example}.

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\linewidth]{segments_image00.jpg}
        \caption{Segmentos detectados imagen 0}
    \end{subfigure}
    \caption{Resultados de la detección de segmentos mediante RANSAC en las imagen 0.}
    \label{fig:kadane_example}
\end{figure}



\end{document}